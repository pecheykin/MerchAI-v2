from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse, FileResponse
import uvicorn
import os
import sqlite3
import uuid
from datetime import datetime
from PIL import Image
import shutil
from typing import List, Optional
import json

# –ò–º–ø–æ—Ä—Ç ML –º–æ–¥–µ–ª–∏
try:
    from pytorch_model import ml_model
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    print("‚ö†Ô∏è  ML –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ - –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥–ª—É—à–∫–∏")

# –ò–º–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø–æ–ª–æ–∫
try:
    from shelf_analyzer import create_shelf_analyzer_with_model
    shelf_analyzer = create_shelf_analyzer_with_model(ml_model) if ML_AVAILABLE else None
    SHELF_ANALYZER_AVAILABLE = True
    print("üõí –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω")
except ImportError:
    shelf_analyzer = None
    SHELF_ANALYZER_AVAILABLE = False
    print("‚ö†Ô∏è  –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ultralytics")

app = FastAPI(title="MerchAI - ML –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ + –ê–Ω–∞–ª–∏–∑ –ø–æ–ª–æ–∫", version="2.1")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
UPLOAD_DIR_TRAIN = "uploads/train"
UPLOAD_DIR_SEARCH = "uploads/search" 
UPLOAD_DIR_SHELF = "uploads/shelf"  # –ù–æ–≤–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –ø–æ–ª–æ–∫
DB_NAME = "merchai_v2.db"
STATIC_DIR = "static"

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
os.makedirs(UPLOAD_DIR_TRAIN, exist_ok=True)
os.makedirs(UPLOAD_DIR_SEARCH, exist_ok=True)
os.makedirs(UPLOAD_DIR_SHELF, exist_ok=True)
os.makedirs(STATIC_DIR, exist_ok=True)
os.makedirs("ml_models", exist_ok=True)
os.makedirs("temp_shelf_analysis", exist_ok=True)

# –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    
    # –¢–∞–±–ª–∏—Ü–∞ —Ç–æ–≤–∞—Ä–æ–≤
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS products (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            description TEXT,
            created_at TEXT NOT NULL
        )
    ''')
    
    # –¢–∞–±–ª–∏—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS training_images (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            product_id INTEGER,
            filename TEXT NOT NULL,
            original_filename TEXT NOT NULL,
            file_size INTEGER,
            created_at TEXT NOT NULL,
            FOREIGN KEY (product_id) REFERENCES products (id)
        )
    ''')
    
    # –¢–∞–±–ª–∏—Ü–∞ ML –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS image_features (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            image_id INTEGER,
            product_id INTEGER,
            features TEXT NOT NULL,
            created_at TEXT NOT NULL,
            FOREIGN KEY (image_id) REFERENCES training_images (id),
            FOREIGN KEY (product_id) REFERENCES products (id)
        )
    ''')
    
    # –ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–æ–≤ –ø–æ–ª–æ–∫
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS shelf_analyses (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            filename TEXT NOT NULL,
            original_filename TEXT NOT NULL,
            analysis_result TEXT NOT NULL,
            created_at TEXT NOT NULL
        )
    ''')
    
    conn.commit()
    conn.close()

def resize_image(image_path: str, size: tuple = (224, 224)):
    """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        with Image.open(image_path) as img:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # –†–µ—Å–∞–π–∑–∏–º
            img_resized = img.resize(size, Image.Resampling.LANCZOS)
            img_resized.save(image_path, 'JPEG', quality=85)
            return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ—Å–∞–π–∑–∞: {e}")
        return False

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    print("üöÄ –ó–∞–ø—É—Å–∫ MerchAI v2.1 - ML + Shelf Analytics")
    init_database()
    print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    if ML_AVAILABLE:
        print("ü§ñ ML –º–æ–¥–µ–ª—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
    else:
        print("‚ö†Ô∏è  ML –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - —Ä–µ–∂–∏–º –∑–∞–≥–ª—É—à–µ–∫")
    
    if SHELF_ANALYZER_AVAILABLE:
        print("üõí –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª–æ–∫ –≥–æ—Ç–æ–≤")
    else:
        print("‚ö†Ô∏è  –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

@app.get("/")
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return {
        "message": "MerchAI v2.1 - ML –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ + –ê–Ω–∞–ª–∏–∑ –ø–æ–ª–æ–∫", 
        "ml_available": ML_AVAILABLE,
        "shelf_analyzer_available": SHELF_ANALYZER_AVAILABLE
    }

# –ü–û–õ–£–ß–ï–ù–ò–ï –°–ü–ò–°–ö–ê –¢–û–í–ê–†–û–í
@app.get("/products/list")
async def get_products():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
    try:
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("SELECT id, name FROM products ORDER BY name")
        products = cursor.fetchall()
        conn.close()
        
        return {
            "products": [{"id": product_id, "name": name} for product_id, name in products]
        }
    except Exception as e:
        return {"products": []}

# –û–ë–£–ß–ï–ù–ò–ï - –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
@app.post("/train/upload")
async def upload_training_data(
    product_name: str = Form(...),
    existing_product_id: Optional[str] = Form(None),
    product_description: str = Form(""),
    files: List[UploadFile] = File(...)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–∞ —Å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    
    try:
        print(f"üîç DEBUG: –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å - —Ç–æ–≤–∞—Ä: '{product_name}', existing_id: {existing_product_id}, —Ñ–∞–π–ª–æ–≤: {len(files) if files else 0}")
        
        if not files:
            raise HTTPException(status_code=400, detail="–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        
        print(f"üîç DEBUG: –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î: {DB_NAME}")
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º product_id
        if existing_product_id:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Ç–æ–≤–∞—Ä—É
            product_id = int(existing_product_id)
            print(f"üîç DEBUG: –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Ç–æ–≤–∞—Ä—É ID: {product_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–æ–≤–∞—Ä —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            cursor.execute("SELECT name FROM products WHERE id = ?", (product_id,))
            result = cursor.fetchone()
            if not result:
                raise HTTPException(status_code=400, detail="–í—ã–±—Ä–∞–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            
            product_name = result[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –ë–î
            print(f"üîç DEBUG: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ –ë–î: {product_name}")
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä
            print(f"üîç DEBUG: –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä –≤ –ë–î")
            cursor.execute(
                "INSERT INTO products (name, created_at) VALUES (?, ?)",
                (product_name, datetime.now().isoformat())
            )
            product_id = cursor.lastrowid
            print(f"üîç DEBUG: –ù–æ–≤—ã–π —Ç–æ–≤–∞—Ä —Å–æ–∑–¥–∞–Ω —Å ID: {product_id}")
        
        uploaded_files = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for i, file in enumerate(files):
            print(f"üîç DEBUG: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª {i+1}: {file.filename}, —Ç–∏–ø: {file.content_type}")
            
            if not file.content_type.startswith('image/'):
                print(f"‚ö†Ô∏è DEBUG: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª {file.filename} - –Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                continue
                
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            file_extension = file.filename.split('.')[-1].lower()
            unique_filename = f"{uuid.uuid4()}.{file_extension}"
            file_path = os.path.join(UPLOAD_DIR_TRAIN, unique_filename)
            
            print(f"üîç DEBUG: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª: {file_path}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(file_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            print(f"üîç DEBUG: –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω, —Ä–∞–∑–º–µ—Ä: {len(content)} –±–∞–π—Ç")
            
            # –†–µ—Å–∞–π–∑–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            print(f"üîç DEBUG: –ù–∞—á–∏–Ω–∞–µ–º —Ä–µ—Å–∞–π–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            if resize_image(file_path):
                file_size = os.path.getsize(file_path)
                print(f"üîç DEBUG: –†–µ—Å–∞–π–∑ —É—Å–ø–µ—à–µ–Ω, –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                print(f"üîç DEBUG: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å—å –≤ training_images")
                cursor.execute(
                    "INSERT INTO training_images (product_id, filename, original_filename, file_size, created_at) VALUES (?, ?, ?, ?, ?)",
                    (product_id, unique_filename, file.filename, file_size, datetime.now().isoformat())
                )
                
                uploaded_files.append({
                    "filename": unique_filename,
                    "original": file.filename,
                    "size": file_size
                })
                print(f"‚úÖ DEBUG: –§–∞–π–ª {file.filename} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
            else:
                print(f"‚ùå DEBUG: –û—à–∏–±–∫–∞ —Ä–µ—Å–∞–π–∑–∞ –¥–ª—è {file.filename}")
                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ —Ä–µ—Å–∞–π–∑ –Ω–µ —É–¥–∞–ª—Å—è
                if os.path.exists(file_path):
                    os.remove(file_path)
        
        print(f"üîç DEBUG: –ö–æ–º–º–∏—Ç–∏–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é")
        conn.commit()
        
        action = "–¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Ç–æ–≤–∞—Ä—É" if existing_product_id else "—Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä"
        result = {
            "status": "success",
            "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({action} '{product_name}')",
            "product_id": product_id,
            "files": uploaded_files
        }
        
        print(f"‚úÖ DEBUG: –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result}")
        return result
        
    except Exception as e:
        print(f"‚ùå –ü–û–õ–ù–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        
        if 'conn' in locals():
            conn.rollback()
            conn.close()
        
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
    
    finally:
        if 'conn' in locals():
            conn.close()
            print(f"üîç DEBUG: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

# –û–ë–£–ß–ï–ù–ò–ï - –∑–∞–ø—É—Å–∫ ML –æ–±—É—á–µ–Ω–∏—è
@app.post("/train/start")
async def start_training():
    """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏"""
    
    if not ML_AVAILABLE:
        return {
            "status": "error", 
            "message": "ML –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (tensorflow, scikit-learn)"
        }
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM training_images")
        image_count = cursor.fetchone()[0]
        conn.close()
        
        if image_count < 2:
            return {
                "status": "error",
                "message": f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {image_count} —Ñ–æ—Ç–æ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2)"
            }
        
        # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
        result = ml_model.train_model(epochs=15, batch_size=8)
        return result
        
    except Exception as e:
        return {
            "status": "error",
            "message": f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}"
        }

# –ü–û–ò–°–ö - –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ—Ç–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–∑–∞–≥–ª—É—à–∫–∞)
@app.post("/search/upload") 
async def search_product_stub(file: UploadFile = File(...)):
    """–ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–∞ –ø–æ —Ñ–æ—Ç–æ (–∑–∞–≥–ª—É—à–∫–∞)"""
    
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    unique_filename = f"{uuid.uuid4()}.jpg"
    temp_path = os.path.join(UPLOAD_DIR_SEARCH, unique_filename)
    
    with open(temp_path, "wb") as buffer:
        content = await file.read()
        buffer.write(content)
    
    file_size = len(content)
    
    # –ó–∞–≥–ª—É—à–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    return {
        "status": "success",
        "message": "–§–æ—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞",
        "filename": unique_filename,
        "file_size": file_size,
        "results": [
            {"product": "–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤", "confidence": 0}
        ]
    }

# –ü–û–ò–°–ö - ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
@app.post("/search/predict")
async def predict_product(file: UploadFile = File(...)):
    """ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –ø–æ —Ñ–æ—Ç–æ"""
    
    if not ML_AVAILABLE:
        return await search_product_stub(file)
    
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    temp_path = f"temp_{uuid.uuid4()}.jpg"
    
    try:
        with open(temp_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        result = ml_model.predict_image(temp_path)
        return result
        
    except Exception as e:
        return {
            "status": "error",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}"
        }
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists(temp_path):
            os.remove(temp_path)

# ===============================================
# –ù–û–í–´–ô –ë–õ–û–ö: –ê–ù–ê–õ–ò–ó –ü–û–õ–û–ö –ú–ê–ì–ê–ó–ò–ù–ê üõí
# ===============================================

@app.post("/shelf/analyze")
async def analyze_shelf(file: UploadFile = File(...)):
    """üõí –ê–ù–ê–õ–ò–ó –ü–û–õ–ö–ò - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–≤–∞—Ä–æ–≤ —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏"""
    
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –ø–æ–ª–∫–∏
    unique_filename = f"shelf_{uuid.uuid4()}.jpg"
    shelf_path = os.path.join(UPLOAD_DIR_SHELF, unique_filename)
    
    try:
        with open(shelf_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        print(f"üõí –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª–∫—É: {file.filename}")
        
        # –®–ê–ì 1: YOLO –¥–µ—Ç–µ–∫—Ü–∏—è —Å –ú–£–õ–¨–¢–ò–§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô
        try:
            from ultralytics import YOLO
            yolo = YOLO('yolov8n.pt')
            
            # üéØ –ù–ê–°–¢–†–û–ô–ö–ò –§–ò–õ–¨–¢–†–ê–¶–ò–ò:
            # conf=0.4 - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–±—ã–ª–æ 0.25)
            # iou=0.5 - —Ñ–∏–ª—å—Ç—Ä –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏—Ö—Å—è –æ–±—ä–µ–∫—Ç–æ–≤  
            # classes=[39,41,47] - —Ç–æ–ª—å–∫–æ bottle, cup, bowl
            results = yolo(shelf_path, conf=0.4, iou=0.5, classes=[39, 41, 47])  # bottle=39, cup=41, bowl=47
            detections = results[0].boxes
            
            if detections is not None and len(detections) > 0:
                # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –†–ê–ó–ú–ï–†–£ –û–ë–™–ï–ö–¢–û–í
                filtered_boxes = []
                image_area = Image.open(shelf_path).size[0] * Image.open(shelf_path).size[1]
                
                for box in detections:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # –†–∞–∑–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞
                    box_width = x2 - x1
                    box_height = y2 - y1
                    box_area = box_width * box_height
                    
                    # –§–ò–õ–¨–¢–†–´:
                    # 1. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–Ω–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π)
                    min_area = image_area * 0.005  # 0.5% –æ—Ç –æ–±—â–µ–π –ø–ª–æ—â–∞–¥–∏
                    # 2. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π) 
                    max_area = image_area * 0.3    # 30% –æ—Ç –æ–±—â–µ–π –ø–ª–æ—â–∞–¥–∏
                    # 3. –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ (–Ω–µ —Å–ª–∏—à–∫–æ–º —É–∑–∫–∏–π/—à–∏—Ä–æ–∫–∏–π)
                    aspect_ratio = box_width / box_height if box_height > 0 else 1
                    
                    if (box_area > min_area and 
                        box_area < max_area and 
                        0.2 < aspect_ratio < 5.0):  # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
                        filtered_boxes.append(box)
                        print(f"‚úÖ –û–±—ä–µ–∫—Ç –ø—Ä–∏–Ω—è—Ç: {box_width:.0f}x{box_height:.0f}, –ø–ª–æ—â–∞–¥—å: {box_area:.0f}")
                    else:
                        print(f"‚ùå –û–±—ä–µ–∫—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω: {box_width:.0f}x{box_height:.0f}, –ø–ª–æ—â–∞–¥—å: {box_area:.0f}")
                
                detections = filtered_boxes
                print(f"üîç –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –æ–±—ä–µ–∫—Ç–æ–≤: {len(detections)}")
            
            
            if len(detections) == 0:
                return {
                    "status": "success",
                    "message": "–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä—ã –Ω–∞ –ø–æ–ª–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
                    "total_objects": 0,
                    "total_recognized": 0,
                    "products": []
                }
            
        except Exception as e:
            return {"status": "error", "message": f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {str(e)}"}
        
        # –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        shelf_image = Image.open(shelf_path)
        recognized_products = []
        
        for i, box in enumerate(detections):
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            confidence_yolo = float(box.conf[0].cpu().numpy())
            
            print(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–∫—Ç {i+1}: YOLO —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence_yolo*100:.1f}%")
            
            # –í—ã—Ä–µ–∑–∞–µ–º –æ–±—ä–µ–∫—Ç
            padding = 15
            crop_box = (
                max(0, int(x1) - padding), max(0, int(y1) - padding), 
                min(shelf_image.width, int(x2) + padding), min(shelf_image.height, int(y2) + padding)
            )
            cropped = shelf_image.crop(crop_box)
            crop_path = f"temp_crop_{i}_{uuid.uuid4().hex[:8]}.jpg"
            cropped.save(crop_path)
            
            try:
                # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ ResNet18
                if ML_AVAILABLE and ml_model:
                    classification = ml_model.predict_image(crop_path)
                    
                    if (classification["status"] == "success" and 
                        classification["results"] and len(classification["results"]) > 0):
                        
                        result = classification["results"][0]
                        product_name = result["product"]
                        confidence = result["confidence"]
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
                        if confidence >= ml_model.confidence_threshold:
                            recognized_products.append(product_name)
                            print(f"‚úÖ –û–±—ä–µ–∫—Ç {i+1}: {product_name} ({confidence:.1f}%)")
                        else:
                            print(f"‚ö†Ô∏è –û–±—ä–µ–∫—Ç {i+1}: {product_name} ({confidence:.1f}%) - —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
                    else:
                        print(f"‚ùå –û–±—ä–µ–∫—Ç {i+1}: –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                else:
                    print(f"‚ùå –û–±—ä–µ–∫—Ç {i+1}: ML –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞ {i+1}: {e}")
            finally:
                if os.path.exists(crop_path):
                    os.remove(crop_path)
        
        # –®–ê–ì 3: –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –¢–û–í–ê–†–ê–ú –° –ü–†–û–¶–ï–ù–¢–ê–ú–ò
        from collections import Counter
        product_counts = Counter(recognized_products)
        
        total_objects = len(detections)
        total_recognized = len(recognized_products)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        products_stats = []
        if total_recognized > 0:
            for product, count in product_counts.most_common():
                percentage = (count / total_recognized) * 100
                products_stats.append({
                    "name": product,
                    "count": count,
                    "percentage": round(percentage, 1)
                })
        
        result = {
            "status": "success",
            "message": f"–ù–∞ –ø–æ–ª–∫–µ –Ω–∞–π–¥–µ–Ω–æ {total_objects} –æ–±—ä–µ–∫—Ç–æ–≤, —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ {total_recognized} —Ç–æ–≤–∞—Ä–æ–≤",
            "total_objects": total_objects,
            "total_recognized": total_recognized,
            "recognition_rate": round((total_recognized / total_objects * 100), 1) if total_objects > 0 else 0,
            "products": products_stats
        }
        
        print(f"üéØ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–õ–ö–ò:")
        print(f"   üì¶ –í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤: {total_objects}")
        print(f"   ‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {total_recognized}")
        for product in products_stats:
            print(f"   ‚Ä¢ {product['name']}: {product['count']} —à—Ç ({product['percentage']}%)")
        
        return result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª–∫–∏: {e}")
        return {"status": "error", "message": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"}

@app.get("/shelf/annotated/{filename}")
async def get_annotated_image(filename: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª–∫–∏"""
    file_path = os.path.join("temp_shelf_analysis", filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    return FileResponse(file_path, media_type="image/jpeg")

@app.get("/shelf/history")
async def get_shelf_analysis_history():
    """–ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤ –ø–æ–ª–æ–∫"""
    try:
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, original_filename, created_at, analysis_result 
            FROM shelf_analyses 
            ORDER BY created_at DESC 
            LIMIT 20
        """)
        
        analyses = []
        for row in cursor.fetchall():
            analysis_id, original_filename, created_at, analysis_result = row
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            try:
                result_data = json.loads(analysis_result)
                summary = {
                    "total_recognized": result_data.get("detection_summary", {}).get("objects_recognized", 0),
                    "recognition_rate": result_data.get("detection_summary", {}).get("recognition_rate_percent", 0)
                }
            except:
                summary = {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç"}
            
            analyses.append({
                "id": analysis_id,
                "filename": original_filename,
                "created_at": created_at,
                "summary": summary
            })
        
        conn.close()
        return {"analyses": analyses}
        
    except Exception as e:
        return {"analyses": [], "error": str(e)}

# ===============================================

# –°–¢–ê–¢–£–° –ú–û–î–ï–õ–ò
@app.get("/model/status")
async def model_status():
    """–°—Ç–∞—Ç—É—Å ML –º–æ–¥–µ–ª–∏"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    model_exists = os.path.exists("pytorch_models/latest_model.pth")
    
    # –°—á–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM training_images")
    image_count = cursor.fetchone()[0]
    cursor.execute("SELECT COUNT(DISTINCT product_id) FROM training_images") 
    product_count = cursor.fetchone()[0]
    
    # –°—á–∏—Ç–∞–µ–º –∞–Ω–∞–ª–∏–∑—ã –ø–æ–ª–æ–∫
    cursor.execute("SELECT COUNT(*) FROM shelf_analyses")
    shelf_analyses_count = cursor.fetchone()[0]
    
    conn.close()
    
    return {
        "ml_available": ML_AVAILABLE,
        "model_trained": model_exists,
        "shelf_analyzer_available": SHELF_ANALYZER_AVAILABLE,
        "training_data": {
            "images": image_count,
            "products": product_count
        },
        "shelf_analyses_count": shelf_analyses_count,
        "ready_for_training": image_count >= 2,
        "ready_for_prediction": model_exists and ML_AVAILABLE,
        "ready_for_shelf_analysis": SHELF_ANALYZER_AVAILABLE and model_exists
    }

# –°–¢–ê–¢–ò–°–¢–ò–ö–ê
@app.get("/stats")
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    cursor.execute("SELECT COUNT(*) FROM products")
    total_products = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM training_images")
    total_images = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM shelf_analyses")
    total_shelf_analyses = cursor.fetchone()[0]
    
    # –ü–æ —Ç–æ–≤–∞—Ä–∞–º
    cursor.execute("""
        SELECT p.name, COUNT(ti.id) as photo_count 
        FROM products p 
        LEFT JOIN training_images ti ON p.id = ti.product_id 
        GROUP BY p.name
    """)
    products_stats = cursor.fetchall()
    
    conn.close()
    
    return {
        "total_products": total_products,
        "total_images": total_images,
        "total_shelf_analyses": total_shelf_analyses,
        "products": [{"name": name, "photos": count} for name, count in products_stats]
    }

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ MerchAI —Å–µ—Ä–≤–µ—Ä–∞ v2.1...")
    uvicorn.run(
        "app:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="debug"
    )