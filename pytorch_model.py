import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.models import resnet18, ResNet18_Weights
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
import sqlite3
import json
import os
import numpy as np
import pandas as pd
import shutil
import matplotlib.pyplot as plt
import matplotlib.style as mplstyle
from typing import List, Dict, Tuple
from datetime import datetime
import random
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

class ProductDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ç–æ–≤–∞—Ä–∞—Ö"""
    
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        if self.transform:
            image = self.transform(image)
        
        label = self.labels[idx]
        return image, label

class EarlyStopping:
    """Early Stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
    def __init__(self, patience=5, min_delta=0.01):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
    
    def __call__(self, val_score):
        if self.best_score is None:
            self.best_score = val_score
        elif val_score < self.best_score + self.min_delta:
            self.counter += 1
            print(f"‚è∞ Early stopping counter: {self.counter}/{self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
                print("üõë Early stopping triggered!")
        else:
            self.best_score = val_score
            self.counter = 0
        
        return self.early_stop

class PytorchMerchML:
    def __init__(self, db_path="merchai_v2.db", model_path="pytorch_models/"):
        self.db_path = db_path
        self.model_path = model_path
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        self.confidence_threshold = 40.0  # ‚Üê –ü–û–†–û–ì –£–í–ï–†–ï–ù–ù–û–°–¢–ò 40%
        
        print(f"üî• –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"üéØ –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {self.confidence_threshold}%")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –º–æ–¥–µ–ª–µ–π
        os.makedirs(model_path, exist_ok=True)
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (—Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π)
        self.train_transform = transforms.Compose([
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ)
        self.val_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        self.predict_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        self.model = None
        self.class_names = []
        self.product_to_label = {}
        self.training_log = []
    
    def get_training_data(self) -> Tuple[List[str], List[int], List[str], Dict]:
        """–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ –ë–î"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ç–æ–≤–∞—Ä–∞–º–∏
        cursor.execute('''
            SELECT ti.filename, p.name, p.id
            FROM training_images ti
            JOIN products p ON ti.product_id = p.id
        ''')
        
        data = cursor.fetchall()
        conn.close()
        
        if not data:
            return [], [], [], {}
        
        # –°–¢–ê–ë–ò–õ–¨–ù–´–ô MAPPING –ö–õ–ê–°–°–û–í
        unique_products = sorted(set([row[1] for row in data]))
        product_to_label = {name: idx for idx, name in enumerate(unique_products)}
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∏ –º–µ—Ç–∫–∏
        image_paths = []
        labels = []
        product_names = []
        
        for filename, product_name, product_id in data:
            file_path = os.path.join("uploads/train", filename)
            
            if os.path.exists(file_path):
                image_paths.append(file_path)
                labels.append(product_to_label[product_name])
                product_names.append(product_name)
        
        self.class_names = unique_products
        self.product_to_label = product_to_label
        
        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Å–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤: {len(unique_products)}")
        print(f"üìä –ö–ª–∞—Å—Å—ã (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã): {unique_products}")
        print(f"üñºÔ∏è  –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_paths)}")
        
        return image_paths, labels, unique_products, product_to_label
    
    def create_model(self, num_classes: int):
        """–°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å ResNet18 - –ü–†–û–í–ï–†–ï–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê!"""
        print(f"üß† –°–æ–∑–¥–∞–µ–º ResNet18 –º–æ–¥–µ–ª—å –¥–ª—è {num_classes} –∫–ª–∞—Å—Å–æ–≤")
        
        # –í–û–ó–í–†–ê–©–ê–ï–ú–°–Ø –ö RESNET18 - –û–ù –ü–û–ö–ê–ó–ê–õ 91%!
        try:
            model = resnet18(weights=ResNet18_Weights.DEFAULT)
            print("‚úÖ ResNet18 –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        except Exception:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–µ—Å–∞ ResNet18, —É—á—É —Å –Ω—É–ª—è")
            model = resnet18(weights=None)
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –í–°–ï —Å–ª–æ–∏ —Å–Ω–∞—á–∞–ª–∞
        for param in model.parameters():
            param.requires_grad = False
        
        # –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø–æ–¥ –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã
        num_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
        
        return model.to(self.device)
    
    def unfreeze_layers(self, model, stage: str):
        """–†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Å–ª–æ–∏ –ø–æ—ç—Ç–∞–ø–Ω–æ –¥–ª—è ResNet18"""
        if stage == "head":
            # –≠—Ç–∞–ø 1: –¢–æ–ª—å–∫–æ –≥–æ–ª–æ–≤–∞ (fc)
            for param in model.fc.parameters():
                param.requires_grad = True
            print("üîì –†–∞–∑–º–æ—Ä–æ–∂–µ–Ω–∞ –≥–æ–ª–æ–≤–∞ ResNet18 (fc)")
            
        elif stage == "layer4":
            # –≠—Ç–∞–ø 2: –ü–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫ + –≥–æ–ª–æ–≤–∞
            for param in model.fc.parameters():
                param.requires_grad = True
            for param in model.layer4.parameters():
                param.requires_grad = True
            # BatchNorm —Å–ª–æ–∏ —Ç–æ–∂–µ trainable
            for module in model.layer4.modules():
                if isinstance(module, nn.BatchNorm2d):
                    module.track_running_stats = True
                    for param in module.parameters():
                        param.requires_grad = True
            print("üîì –†–∞–∑–º–æ—Ä–æ–∂–µ–Ω—ã layer4 + fc (+ BatchNorm)")
            
        elif stage == "deep":
            # –≠—Ç–∞–ø 3: layer3 + layer4 + –≥–æ–ª–æ–≤–∞
            for param in model.fc.parameters():
                param.requires_grad = True
            for param in model.layer4.parameters():
                param.requires_grad = True
            for param in model.layer3.parameters():
                param.requires_grad = True
                
            # BatchNorm –¥–ª—è layer3 –∏ layer4
            for module in model.layer4.modules():
                if isinstance(module, nn.BatchNorm2d):
                    module.track_running_stats = True
                    for param in module.parameters():
                        param.requires_grad = True
            for module in model.layer3.modules():
                if isinstance(module, nn.BatchNorm2d):
                    module.track_running_stats = True
                    for param in module.parameters():
                        param.requires_grad = True
            print("üîì –†–∞–∑–º–æ—Ä–æ–∂–µ–Ω—ã layer3 + layer4 + fc (–≥–ª—É–±–æ–∫–∏–π fine-tuning + BatchNorm)")
    
    def evaluate_model(self, model, val_loader, criterion):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, targets in val_loader:
                images = images.to(self.device)
                targets = targets.to(self.device)
                
                outputs = model(images)
                loss = criterion(outputs, targets)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += targets.size(0)
                val_correct += (predicted == targets).sum().item()
        
        val_accuracy = 100 * val_correct / val_total
        avg_val_loss = val_loss / len(val_loader)
        
        return val_accuracy, avg_val_loss
    
    def save_training_log(self, timestamp: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è –≤ CSV/JSON"""
        if not self.training_log:
            return
            
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV –¥–ª—è –ª–µ–≥–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        df = pd.DataFrame(self.training_log)
        csv_file = os.path.join(self.model_path, f"training_log_{timestamp}.csv")
        df.to_csv(csv_file, index=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        json_file = os.path.join(self.model_path, f"training_log_{timestamp}.json")
        with open(json_file, 'w') as f:
            json.dump(self.training_log, f, indent=2)
            
        print(f"üìä –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {csv_file}, {json_file}")
        return csv_file, df
    
    def plot_training_curves(self, df: pd.DataFrame, timestamp: str):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            if len(df) < 3:
                print("‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ (< 3 —ç–ø–æ—Ö)")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è matplotlib
            plt.style.use('default')
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ResNet18 + –ø–æ—Ä–æ–≥ 40% - {timestamp}', fontsize=16, fontweight='bold')
            
            # –¶–≤–µ—Ç–∞ –¥–ª—è —ç—Ç–∞–ø–æ–≤
            stage_colors = {'head': '#FF6B6B', 'layer4': '#4ECDC4', 'deep': '#45B7D1'}
            
            # –ì—Ä–∞—Ñ–∏–∫ 1: Train Loss
            for stage in df['stage'].unique():
                stage_data = df[df['stage'] == stage]
                ax1.plot(stage_data['epoch'], stage_data['train_loss'], 
                        color=stage_colors.get(stage, '#666'), 
                        marker='o', linewidth=2, markersize=4,
                        label=f'{stage} stage')
            ax1.set_title('Train Loss', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: Validation Loss  
            for stage in df['stage'].unique():
                stage_data = df[df['stage'] == stage]
                ax2.plot(stage_data['epoch'], stage_data['val_loss'], 
                        color=stage_colors.get(stage, '#666'), 
                        marker='s', linewidth=2, markersize=4,
                        label=f'{stage} stage')
            ax2.set_title('Validation Loss', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Loss')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 3: Train Accuracy
            for stage in df['stage'].unique():
                stage_data = df[df['stage'] == stage]
                ax3.plot(stage_data['epoch'], stage_data['train_accuracy'], 
                        color=stage_colors.get(stage, '#666'), 
                        marker='o', linewidth=2, markersize=4,
                        label=f'{stage} stage')
            ax3.set_title('Train Accuracy', fontsize=14, fontweight='bold')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Accuracy (%)')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 4: Validation Accuracy
            for stage in df['stage'].unique():
                stage_data = df[df['stage'] == stage]
                ax4.plot(stage_data['epoch'], stage_data['val_accuracy'], 
                        color=stage_colors.get(stage, '#666'), 
                        marker='s', linewidth=2, markersize=4,
                        label=f'{stage} stage')
            ax4.set_title('Validation Accuracy', fontsize=14, fontweight='bold')
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('Accuracy (%)')
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ –¥–ª—è —Å–º–µ–Ω—ã —ç—Ç–∞–ø–æ–≤
            stage_changes = df.groupby('stage')['epoch'].min().values[1:]
            for ax in [ax1, ax2, ax3, ax4]:
                for change_epoch in stage_changes:
                    ax.axvline(x=change_epoch, color='red', linestyle='--', alpha=0.7, linewidth=1)
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            plot_file = os.path.join(self.model_path, f"training_curves_{timestamp}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìà –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {plot_file}")
            return plot_file
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏: {e}")
            return None
    
    def train_model(self, epochs=15, batch_size=8, learning_rate=0.001, early_stop_patience=5) -> Dict:
        """–û–±—É—á–∞–µ–º ResNet18 –º–æ–¥–µ–ª—å - –ü–†–û–í–ï–†–ï–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê 91%"""
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ ResNet18 + –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ 40%...")
        
        # –û—á–∏—â–∞–µ–º –ª–æ–≥ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        self.training_log = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        image_paths, labels, class_names, product_to_label = self.get_training_data()
        
        if len(image_paths) == 0:
            return {
                "status": "error",
                "message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
            }
        
        if len(set(labels)) < 2:
            return {
                "status": "error", 
                "message": f"–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –∫–ª–∞—Å—Å–∞ —Ç–æ–≤–∞—Ä–æ–≤, –Ω–∞–π–¥–µ–Ω–æ: {len(set(labels))}"
            }
        
        num_classes = len(class_names)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å ResNet18
        self.model = self.create_model(num_classes)
        
        # TRAIN/VAL SPLIT
        full_dataset = ProductDataset(image_paths, labels, self.train_transform)
        
        # –î–µ–ª–∏–º –Ω–∞ train/val (80/20)
        val_size = int(0.2 * len(full_dataset))
        train_size = len(full_dataset) - val_size
        
        # –§–∏–∫—Å–∏—Ä—É–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        torch.manual_seed(42)
        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
        
        # –î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        val_indices = val_dataset.indices
        val_dataset = ProductDataset(
            [image_paths[i] for i in val_indices],
            [labels[i] for i in val_indices], 
            self.val_transform
        )
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        print(f"üìä Train: {len(train_dataset)}, Val: {len(val_dataset)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π –ø–æ—Ç–µ—Ä—å –∏ Early Stopping
        criterion = nn.CrossEntropyLoss()
        early_stopping = EarlyStopping(patience=early_stop_patience, min_delta=0.01)
        
        # –¢–†–ï–•–≠–¢–ê–ü–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –° EARLY STOPPING
        best_val_acc = 0.0
        total_epochs_trained = 0
        
        # –≠–¢–ê–ü 1: –û–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ–≤—É (–¥–æ 5 —ç–ø–æ—Ö —Å early stopping)
        print("\nüéØ –≠–¢–ê–ü 1: –û–±—É—á–µ–Ω–∏–µ –≥–æ–ª–æ–≤—ã ResNet18 (frozen backbone)")
        self.unfreeze_layers(self.model, "head")
        
        optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
        
        stage1_epochs = 0
        for epoch in range(5):
            self.model.train()
            epoch_loss = 0
            epoch_correct = 0
            epoch_total = 0
            
            for batch_idx, (images, targets) in enumerate(train_loader):
                images = images.to(self.device)
                targets = targets.to(self.device)
                
                optimizer.zero_grad()
                outputs = self.model(images)
                loss = criterion(outputs, targets)
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                epoch_total += targets.size(0)
                epoch_correct += (predicted == targets).sum().item()
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            val_accuracy, val_loss = self.evaluate_model(self.model, val_loader, criterion)
            train_accuracy = 100 * epoch_correct / epoch_total
            avg_loss = epoch_loss / len(train_loader)
            
            # –õ–û–ì–ò–†–£–ï–ú –ú–ï–¢–†–ò–ö–ò
            self.training_log.append({
                "epoch": epoch + 1,
                "stage": "head",
                "train_loss": avg_loss,
                "train_accuracy": train_accuracy,
                "val_loss": val_loss,
                "val_accuracy": val_accuracy,
                "learning_rate": optimizer.param_groups[0]['lr']
            })
            
            print(f"‚úÖ –≠–ø–æ—Ö–∞ {epoch+1}/5: Train Loss={avg_loss:.4f}, Train Acc={train_accuracy:.2f}%, Val Acc={val_accuracy:.2f}%")
            
            scheduler.step(val_accuracy)
            stage1_epochs = epoch + 1
            total_epochs_trained += 1
            
            if val_accuracy > best_val_acc:
                best_val_acc = val_accuracy
            
            # Early stopping check
            if early_stopping(val_accuracy):
                print(f"üõë Early stopping –Ω–∞ —ç—Ç–∞–ø–µ 1 –ø–æ—Å–ª–µ {stage1_epochs} —ç–ø–æ—Ö")
                break
        
        # –≠–¢–ê–ü 2: layer4 + fc (–¥–æ 5 —ç–ø–æ—Ö —Å early stopping)
        remaining_epochs = epochs - total_epochs_trained
        if remaining_epochs > 0 and not early_stopping.early_stop:
            stage2_epochs_max = min(5, remaining_epochs)
            print(f"\nüî• –≠–¢–ê–ü 2: Fine-tuning layer4 + fc ResNet18 - –¥–æ {stage2_epochs_max} —ç–ø–æ—Ö")
            self.unfreeze_layers(self.model, "layer4")
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º early stopping –¥–ª—è –Ω–æ–≤–æ–≥–æ —ç—Ç–∞–ø–∞
            early_stopping = EarlyStopping(patience=early_stop_patience, min_delta=0.01)
            optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=learning_rate * 0.1)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)
            
            stage2_epochs = 0
            for epoch in range(stage2_epochs_max):
                self.model.train()
                epoch_loss = 0
                epoch_correct = 0
                epoch_total = 0
                
                for batch_idx, (images, targets) in enumerate(train_loader):
                    images = images.to(self.device)
                    targets = targets.to(self.device)
                    
                    optimizer.zero_grad()
                    outputs = self.model(images)
                    loss = criterion(outputs, targets)
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    epoch_total += targets.size(0)
                    epoch_correct += (predicted == targets).sum().item()
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è
                val_accuracy, val_loss = self.evaluate_model(self.model, val_loader, criterion)
                train_accuracy = 100 * epoch_correct / epoch_total
                avg_loss = epoch_loss / len(train_loader)
                
                current_epoch = total_epochs_trained + epoch + 1
                
                # –õ–û–ì–ò–†–£–ï–ú –ú–ï–¢–†–ò–ö–ò
                self.training_log.append({
                    "epoch": current_epoch,
                    "stage": "layer4",
                    "train_loss": avg_loss,
                    "train_accuracy": train_accuracy,
                    "val_loss": val_loss,
                    "val_accuracy": val_accuracy,
                    "learning_rate": optimizer.param_groups[0]['lr']
                })
                
                print(f"üî• –≠–ø–æ—Ö–∞ {current_epoch}/{epochs}: Train Loss={avg_loss:.4f}, Train Acc={train_accuracy:.2f}%, Val Acc={val_accuracy:.2f}%")
                
                scheduler.step(val_accuracy)
                stage2_epochs = epoch + 1
                total_epochs_trained += 1
                
                if val_accuracy > best_val_acc:
                    best_val_acc = val_accuracy
                
                # Early stopping check
                if early_stopping(val_accuracy):
                    print(f"üõë Early stopping –Ω–∞ —ç—Ç–∞–ø–µ 2 –ø–æ—Å–ª–µ {stage2_epochs} —ç–ø–æ—Ö")
                    break
        
        # –≠–¢–ê–ü 3: –ì–ª—É–±–æ–∫–∏–π fine-tuning layer3 + layer4 + fc (–æ—Å—Ç–∞–≤—à–∏–µ—Å—è —ç–ø–æ—Ö–∏)
        remaining_epochs = epochs - total_epochs_trained
        if remaining_epochs > 0 and not early_stopping.early_stop:
            print(f"\nüí• –≠–¢–ê–ü 3: –ì–ª—É–±–æ–∫–∏–π fine-tuning ResNet18 - –¥–æ {remaining_epochs} —ç–ø–æ—Ö")
            self.unfreeze_layers(self.model, "deep")
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º early stopping –¥–ª—è –Ω–æ–≤–æ–≥–æ —ç—Ç–∞–ø–∞
            early_stopping = EarlyStopping(patience=early_stop_patience, min_delta=0.01)
            optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=learning_rate * 0.01)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)
            
            for epoch in range(remaining_epochs):
                self.model.train()
                epoch_loss = 0
                epoch_correct = 0
                epoch_total = 0
                
                for batch_idx, (images, targets) in enumerate(train_loader):
                    images = images.to(self.device)
                    targets = targets.to(self.device)
                    
                    optimizer.zero_grad()
                    outputs = self.model(images)
                    loss = criterion(outputs, targets)
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    epoch_total += targets.size(0)
                    epoch_correct += (predicted == targets).sum().item()
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è
                val_accuracy, val_loss = self.evaluate_model(self.model, val_loader, criterion)
                train_accuracy = 100 * epoch_correct / epoch_total
                avg_loss = epoch_loss / len(train_loader)
                
                current_epoch = total_epochs_trained + epoch + 1
                
                # –õ–û–ì–ò–†–£–ï–ú –ú–ï–¢–†–ò–ö–ò
                self.training_log.append({
                    "epoch": current_epoch,
                    "stage": "deep",
                    "train_loss": avg_loss,
                    "train_accuracy": train_accuracy,
                    "val_loss": val_loss,
                    "val_accuracy": val_accuracy,
                    "learning_rate": optimizer.param_groups[0]['lr']
                })
                
                print(f"üí• –≠–ø–æ—Ö–∞ {current_epoch}/{epochs}: Train Loss={avg_loss:.4f}, Train Acc={train_accuracy:.2f}%, Val Acc={val_accuracy:.2f}%")
                
                scheduler.step(val_accuracy)
                total_epochs_trained += 1
                
                if val_accuracy > best_val_acc:
                    best_val_acc = val_accuracy
                
                # Early stopping check
                if early_stopping(val_accuracy):
                    print(f"üõë Early stopping –Ω–∞ —ç—Ç–∞–ø–µ 3 –ø–æ—Å–ª–µ {epoch + 1} —ç–ø–æ—Ö")
                    break
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        model_filename = f"resnet18_threshold40_epoch{total_epochs_trained}_acc{best_val_acc:.1f}_{timestamp}.pth"
        model_file = os.path.join(self.model_path, model_filename)
        classes_file = os.path.join(self.model_path, "class_names.json")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'class_names': class_names,
            'product_to_label': product_to_label,
            'num_classes': num_classes,
            'val_accuracy': best_val_acc,
            'epochs': total_epochs_trained,
            'timestamp': timestamp,
            'training_log': self.training_log,
            'early_stopped': early_stopping.early_stop,
            'architecture': 'ResNet18',
            'confidence_threshold': self.confidence_threshold
        }, model_file)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ
        with open(classes_file, 'w', encoding='utf-8') as f:
            json.dump({
                'class_names': class_names,
                'product_to_label': product_to_label,
                'architecture': 'ResNet18',
                'confidence_threshold': self.confidence_threshold
            }, f, ensure_ascii=False, indent=2)
        
        # –ö–†–û–°–°–ü–õ–ê–¢–§–û–†–ú–ï–ù–ù–ê–Ø –ö–û–ü–ò–Ø
        latest_link = os.path.join(self.model_path, "latest_model.pth")
        try:
            shutil.copy2(model_file, latest_link)
            print(f"üìé –ö–æ–ø–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–æ–¥–µ–ª–∏ ResNet18: {latest_link}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–ø–∏—é latest_model.pth: {e}")
        
        # –°–û–•–†–ê–ù–Ø–ï–ú –õ–û–ì–ò –û–ë–£–ß–ï–ù–ò–Ø –ò –°–¢–†–û–ò–ú –ì–†–ê–§–ò–ö–ò
        csv_file, df = self.save_training_log(timestamp)
        plot_file = self.plot_training_curves(df, timestamp)
        
        result = {
            "status": "success",
            "message": f"–ú–æ–¥–µ–ª—å ResNet18 –æ–±—É—á–µ–Ω–∞! –õ—É—á—à–∞—è Val —Ç–æ—á–Ω–æ—Å—Ç—å: {best_val_acc:.2f}% (–ø–æ—Ä–æ–≥ {self.confidence_threshold}%)",
            "val_accuracy": best_val_acc,
            "epochs": total_epochs_trained,
            "planned_epochs": epochs,
            "early_stopped": early_stopping.early_stop,
            "num_classes": num_classes,
            "total_samples": len(image_paths),
            "class_names": class_names,
            "model_file": model_filename,
            "training_stages": len(set([log["stage"] for log in self.training_log])),
            "plot_file": plot_file,
            "architecture": "ResNet18",
            "confidence_threshold": self.confidence_threshold
        }
        
        print(f"üéâ –û–±—É—á–µ–Ω–∏–µ ResNet18 –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –õ—É—á—à–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_val_acc:.2f}%")
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_file}")
        print(f"üéØ –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {self.confidence_threshold}%")
        if early_stopping.early_stop:
            print(f"üõë –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –¥–æ—Å—Ä–æ—á–Ω–æ –ø–æ—Å–ª–µ {total_epochs_trained} —ç–ø–æ—Ö")
        return result
    
    def load_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ –∫–æ–ø–∏—é latest
        latest_link = os.path.join(self.model_path, "latest_model.pth")
        model_file = latest_link
        
        if not os.path.exists(model_file):
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ø–∏–∏, –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å –ø–æ –¥–∞—Ç–µ
            model_files = [f for f in os.listdir(self.model_path) 
                          if f.startswith("resnet18") and f.endswith(".pth")]
            if not model_files:
                print("‚ùå –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            model_files.sort(key=lambda x: os.path.getmtime(os.path.join(self.model_path, x)), reverse=True)
            model_file = os.path.join(self.model_path, model_files[0])
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
            checkpoint = torch.load(model_file, map_location=self.device)
            
            self.class_names = checkpoint['class_names']
            self.product_to_label = checkpoint.get('product_to_label', {})
            num_classes = checkpoint['num_classes']
            architecture = checkpoint.get('architecture', 'ResNet18')
            self.confidence_threshold = checkpoint.get('confidence_threshold', 40.0)
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = self.create_model(num_classes)
            
            # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            self.unfreeze_layers(self.model, "deep")
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            val_acc = checkpoint.get('val_accuracy', 'N/A')
            early_stopped = checkpoint.get('early_stopped', False)
            training_stages = len(set([log["stage"] for log in checkpoint.get('training_log', [])]))
            
            print(f"‚úÖ –ú–æ–¥–µ–ª—å {architecture} –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(self.class_names)} –∫–ª–∞—Å—Å–æ–≤, Val —Ç–æ—á–Ω–æ—Å—Ç—å: {val_acc}%")
            print(f"üìä –≠—Ç–∞–ø–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {training_stages}, Early stopped: {early_stopped}")
            print(f"üéØ –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {self.confidence_threshold}%")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def predict_image(self, image_path: str, top_k: int = 3) -> Dict:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –° –ü–û–†–û–ì–û–ú –£–í–ï–†–ï–ù–ù–û–°–¢–ò 40%"""
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.model is None:
            if not self.load_model():
                return {
                    "status": "error",
                    "message": "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /train/start"
                }
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.predict_transform(image).unsqueeze(0).to(self.device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-K –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                top_probs, top_indices = torch.topk(probabilities, min(top_k, len(self.class_names)))
                
                results = []
                max_confidence = float(top_probs[0].item() * 100)
                
                # üéØ –ü–†–ò–ú–ï–ù–Ø–ï–ú –ü–û–†–û–ì –£–í–ï–†–ï–ù–ù–û–°–¢–ò 40%
                if max_confidence < self.confidence_threshold:
                    results.append({
                        "product": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä",
                        "confidence": max_confidence
                    })
                    print(f"‚ö†Ô∏è –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {max_confidence:.1f}% < {self.confidence_threshold}% - —Ç–æ–≤–∞—Ä –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")
                else:
                    for prob, idx in zip(top_probs, top_indices):
                        confidence = float(prob.item() * 100)
                        if confidence >= self.confidence_threshold:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ >= –ø–æ—Ä–æ–≥–∞
                            results.append({
                                "product": self.class_names[idx.item()],
                                "confidence": confidence
                            })
            
            result = {
                "status": "success", 
                "results": results,
                "confidence_threshold": self.confidence_threshold
            }
            
            print(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ResNet18 + –ø–æ—Ä–æ–≥ {self.confidence_threshold}%: {results}")
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {
                "status": "error",
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}"
            }

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
ml_model = PytorchMerchML()